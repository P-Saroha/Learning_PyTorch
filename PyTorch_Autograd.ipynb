{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Basics of Autograd\n",
        "## PyTorch tracks operations on tensors with the attribute requires_grad=True. When operations are performed on these tensors, PyTorch builds a computation graph dynamically and allows automatic differentiation."
      ],
      "metadata": {
        "id": "E7y7iP6FWEB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a tensor with requires_grad=True\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# Perform operations\n",
        "y = x ** 2  # y = x^2\n",
        "\n",
        "# Compute gradients\n",
        "y.backward()\n",
        "\n",
        "# Gradient of y w.r.t x (dy/dx = 2x)\n",
        "print(x.grad)  # Output: tensor(6.)\n",
        "\n"
      ],
      "metadata": {
        "id": "TvT8eCj-YRja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "## requires_grad=True enables gradient tracking.\n",
        "\n",
        "## .backward() computes gradients.\n",
        "\n",
        "## zero_grad() clears gradients.\n",
        "\n",
        "## no_grad() disables tracking for performance.\n",
        "\n",
        "## detach() creates a tensor without gradient tracking.\n",
        "\n",
        "## autograd.grad() computes derivatives explicitly."
      ],
      "metadata": {
        "id": "JcKuqft4YlsZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "YDGC63EJDuUx"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "IjvoFgemWd2m"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**3"
      ],
      "metadata": {
        "id": "IDhV_qo1Wu1F"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDh08xnxW1ic",
        "outputId": "ac15dfa2-d833-42cf-dbc1-ea93dfd5db37"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "FpD5vXy3W240"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy6TMssxX3Q2",
        "outputId": "b24c7975-c6da-4ed6-fcb6-8b19da22e054"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12.)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## another example\n",
        "a = torch.tensor(2.0 , requires_grad=True)"
      ],
      "metadata": {
        "id": "H-AVFpzlX5GT"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = a**2"
      ],
      "metadata": {
        "id": "ipRRgRBpZYB6"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.sin(b)"
      ],
      "metadata": {
        "id": "cHaLKbRhZjRI"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e4aifnzbM-A",
        "outputId": "3d50d1e1-9c49-4f24-b955-03b0b072e7ec"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNl9NYt7ZncR",
        "outputId": "7cd43331-623c-4129-8d3f-8ea9fd5c3ce6"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lMrcveWbSgq",
        "outputId": "6c84a294-343f-4620-a804-fa74ee45725e"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.7568, grad_fn=<SinBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a ---> square ----> b -----> sin ------> z\n",
        "\n",
        "## now find dz/da ??\n",
        "## dz/db --> db/da ----> answer"
      ],
      "metadata": {
        "id": "2-xKMKpjZ8sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()"
      ],
      "metadata": {
        "id": "YW4SNIcGZrfa"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6zARR5za93u",
        "outputId": "d76a12e3-7e16-49bb-b58e-0c44ab430e34"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.6146)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uO7d2YpLeyJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(6.7)\n",
        "y = torch.tensor(0.0)"
      ],
      "metadata": {
        "id": "ltdM3W8Na_kE"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = torch.tensor(1.0, requires_grad= True)\n",
        "bias = torch.tensor(0.0 , requires_grad=True)"
      ],
      "metadata": {
        "id": "HodYbVJWe9jI"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiJ7hinifMzn",
        "outputId": "88762419-6a56-428d-e916-3863df577933"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mFQZDBkfUhD",
        "outputId": "e3219a6e-7c55-46b8-ee1f-87be63ce896a"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## forword propogation\n",
        "z = weight*x + bias\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2HzrDyVfVXU",
        "outputId": "5bc57a72-1d6a-4377-ad1d-5206c9d684e9"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.7000, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## sigmoid\n",
        "y_pred = torch.sigmoid(z)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB_LWfo1fkZg",
        "outputId": "0411066f-65eb-4412-e899-6d41001128b1"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## loss\n",
        "import torch.nn.functional as F\n",
        "loss = F.binary_cross_entropy(y_pred, y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX3NM_Kgf2pR",
        "outputId": "56897e63-f0d5-463a-ad61-a1f3bdf2748c"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.7012, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "Qh84FctqgFlK"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(weight.grad)\n",
        "print(bias.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyHSmZzChQlH",
        "outputId": "97563568-f73e-4141-bc54-250e2a8af64b"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.6918)\n",
            "tensor(0.9988)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0,1.1,2.2,3.3], requires_grad=True)"
      ],
      "metadata": {
        "id": "-wLY4oaehkhu"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs0mu85RvznK",
        "outputId": "ac914c71-c2e3-4d73-8a64-9f69bf1897a2"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 1.1000, 2.2000, 3.3000], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = (x**2).mean()"
      ],
      "metadata": {
        "id": "3V3t3TGyv0iz"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg_27Ds6v8Ct",
        "outputId": "e448d870-b9d9-45e4-e3ff-e7719e26ffe3"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.2350, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "XxUNJ8r-v8sw"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9WBQRRNwDN5",
        "outputId": "7216245b-f0a6-4c1a-d40e-a74fc1da2028"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.5500, 1.1000, 1.6500])"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clearing Gradients in PyTorch\n",
        "PyTorch accumulates gradients by default instead of replacing them in each backward pass. To prevent unwanted gradient accumulation, you need to clear gradients manually before calling .backward()."
      ],
      "metadata": {
        "id": "VeyhNP4RxhAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## clearing grad\n",
        "x = torch.tensor(2.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "vA_Dsa2LwLAb"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2"
      ],
      "metadata": {
        "id": "Wor1s0JQxyT0"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "ZQcCKKobx0pS"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPo8MWbwx3L8",
        "outputId": "34629588-8cd3-4f71-ef16-09c402af2652"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear gradients\n",
        "# optimizer.zero_grad()\n",
        "x.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NZ9m_c2x6Gm",
        "outputId": "6c5179d6-b8f8-4a5d-b7c1-bcf5ad1842e5"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##v1. Using torch.no_grad() (Recommended for Inference)\n",
        "✅ Best for model inference when you don’t need gradients.\n",
        "✅ Reduces memory usage and speeds up computations."
      ],
      "metadata": {
        "id": "_fWQPmkl0iW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example tensor with requires_grad=True\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "\n",
        "# Normal forward pass (gradients tracked)\n",
        "y = x * 2\n",
        "print(y.requires_grad)  # Output: True\n",
        "\n",
        "# Forward pass with no gradient tracking\n",
        "with torch.no_grad():\n",
        "    y_no_grad = x * 2\n",
        "    print(y_no_grad.requires_grad)  # Output: False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfakXk_EyHWd",
        "outputId": "d5024665-51f2-4339-f4a7-a882101e6cb4"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Using detach() (For Detaching Tensor From Computation Graph)\n",
        "✅ Creates a new tensor that does not require gradients.\n",
        "✅ Useful when you want to prevent gradient updates for specific tensors."
      ],
      "metadata": {
        "id": "E3cxnFqv0vZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "y = x * 2\n",
        "\n",
        "# Detach y from computation graph\n",
        "y_detached = y.detach()\n",
        "print(y_detached.requires_grad)  # Output: False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvy3tOyI0n4-",
        "outputId": "234b0cd4-28c8-439b-b7d3-5b0f908f7845"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Using requires_grad_(False) (For Freezing Model Parameters)\n",
        "✅ Modifies an existing tensor or model parameter to stop tracking gradients.\n",
        "✅ Useful for freezing model layers during transfer learning."
      ],
      "metadata": {
        "id": "HgX_vihg04ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "model = nn.Linear(10, 1)\n",
        "\n",
        "# Freeze model parameters (disable gradient tracking)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad_(False)\n",
        "\n",
        "# Check if gradients are disabled\n",
        "print([param.requires_grad for param in model.parameters()])  # Output: [False, False]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErGPtFTu013H",
        "outputId": "bb714dda-a251-4b17-ac3a-bf527ff80da9"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRtTlmUA1ATi"
      },
      "execution_count": 193,
      "outputs": []
    }
  ]
}